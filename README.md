# Comparative Analysis of Manual and LLM-Based Knowledge Graph Generation for Question Answering Systems

## Project Description
This project aims to compare manually created knowledge graphs with those automatically generated by Gemma 7B V0 which running with Ollama, a large language model (LLM). The comparison seeks to highlight the differences and similarities, performance, advantages and disadvantages between manually curated knowledge graphs and those created by an LLM, providing valuable insights for knowledge graph generation.

## Requirements
This project requires Python 3.12.0 All dependencies can be installed via the `requirements.txt` file.

### Installation Instructions
1. Create and activate a virtual environment or Create Pyenv environment to run the analysis:

2. Install the necessary dependencies:
    ```bash
    pip install -r requirements.txt
    ```
3. Finally, you should search ollama Gemma 7B model script on documentation after that you can run the the model to use for the project.

## Project Usage
1. Download and set up the Ollama Gemma 7B model, following the official Ollama documentation. More details can be found [here](https://ollama.com/).

2. Run the analysis to compare automatically generated knowledge graphs with manually created ones.

## Academic Relevance
This project provides an empirical framework for analyzing the efficiency and accuracy of automated knowledge graph generation using large language models. The comparison may offer new insights into how machine-generated graphs can complement or improve existing manual methodologies.

## Further Reading
- **Ollama Gemma 7B Model Documentation:** [Ollama Official Website](https://ollama.com)
- **Python Official Documentation:** [Python Documentation](https://docs.python.org/3/)
